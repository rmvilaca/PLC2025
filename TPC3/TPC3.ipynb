{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8dcbdd",
   "metadata": {},
   "source": [
    "# TPC4 - Analisador Léxico\n",
    "\n",
    "Construir um analisador léxico para uma liguagem de query com a qual se podem escrever frases do\n",
    "género:\n",
    "\n",
    " DBPedia: obras de Chuck Berry \n",
    " \n",
    "\n",
    "```sparql\n",
    "\n",
    "select ?nome ?desc where { \n",
    "    ?s a dbo:MusicalArtist. \n",
    "    ?s foaf:name \"Chuck Berry\"@en . \n",
    "    ?w dbo:artist ?s. \n",
    "    ?w foaf:name ?nome. \n",
    "    ?w dbo:abstract ?desc \n",
    "} LIMIT 1000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3e2bfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SELECT', 'SELECT', 1, (0, 6)),\n",
       " ('VAR', '?nome', 1, (7, 12)),\n",
       " ('VAR', '?Tomas', 1, (13, 19)),\n",
       " ('VAR', '?tudo', 1, (20, 25)),\n",
       " ('WHERE', 'WHERE', 1, (27, 32)),\n",
       " ('NEWLINE', '\\n', 2, (33, 34)),\n",
       " ('PUNCT', '{', 2, (34, 35)),\n",
       " ('NEWLINE', '\\n', 3, (35, 36)),\n",
       " ('VAR', '?ola', 3, (38, 42)),\n",
       " ('ERROR', 'a', 3, (43, 44)),\n",
       " ('IDENT', ':Pessoa', 3, (45, 52)),\n",
       " ('PUNCT', ';', 3, (53, 54)),\n",
       " ('NEWLINE', '\\n', 4, (54, 55)),\n",
       " ('IDENT', ':temIdade', 4, (60, 69)),\n",
       " ('ERROR', '?', 4, (70, 71)),\n",
       " ('INT', '26', 4, (71, 73)),\n",
       " ('PUNCT', ';', 4, (74, 75)),\n",
       " ('NEWLINE', '\\n', 5, (75, 76)),\n",
       " ('IDENT', ':eIrmaoDe', 5, (81, 90)),\n",
       " ('VAR', '?Tomas', 5, (91, 97)),\n",
       " ('PUNCT', '.', 5, (98, 99)),\n",
       " ('NEWLINE', '\\n', 6, (99, 100)),\n",
       " ('PUNCT', '}', 6, (100, 101)),\n",
       " ('NEWLINE', '\\n', 7, (101, 102))]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(input):\n",
    "\n",
    "    tokens=[\n",
    "    ('NEWLINE',r'\\n'),\n",
    "    ('SKIP',r'[ \\t]+'),\n",
    "    ('PREFIX',r'PREFIX\\b'),\n",
    "    ('SELECT',r'SELECT\\b'),\n",
    "    ('WHERE',r'WHERE\\b'),\n",
    "    ('OPTIOMAL',r'OPTIONAL\\b'),\n",
    "    ('FILTER',r'FILTER\\b'),\n",
    "    ('VAR',r'\\?[a-zA-Z_][\\w]*'),\n",
    "    ('URI',r'<[^>]*>'),\n",
    "    ('IDENT',r':[a-zA-Z_][\\w]*'),\n",
    "    ('INT',r'\\d+'),\n",
    "    ('STRING',r'\"[^\"]*\"'),\n",
    "    ('OP',r'[=!<>]+'),\n",
    "    ('PUNCT',r'[{}.;,]'),\n",
    "    ('ERROR',r'.')\n",
    "]\n",
    "    \n",
    "    reconhecidos=[]\n",
    "    linha=1 \n",
    "    tokenreg='|'.join(f'(?P<{name}>{pattern})'for name , pattern in tokens) \n",
    "    val=re.finditer(tokenreg,input)\n",
    "    for v in val:\n",
    "        dic=v.groupdict()\n",
    "        tipo=None\n",
    "        valor=v.group()\n",
    "        for key in dic:\n",
    "            if dic[key]:\n",
    "                tipo=key\n",
    "                break\n",
    "        if tipo=='NEWLINE':\n",
    "            linha+=1\n",
    "            reconhecidos.append((tipo, valor, linha, v.span()))\n",
    "        elif tipo != 'SKIP':\n",
    "            reconhecidos.append((tipo, valor, linha, v.span()))\n",
    "            \n",
    "    return reconhecidos\n",
    "    print (reconhecidos)\n",
    "\n",
    "    input = \"\"\"SELECT ?nome ?Tomas ?tudo  WHERE \n",
    "{\n",
    "  ?ola a :Pessoa ;\n",
    "     :temIdade ?26 ;\n",
    "     :eIrmaoDe ?Tomas .\n",
    "}\n",
    "\"\"\"\n",
    "tokenize(input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
